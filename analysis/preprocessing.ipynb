{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "1. Convert text to lowercase \n",
    "2. Remove URLs, mentions, and special characters (besides hashtags and emojis)\n",
    "3. Remove stop words\n",
    "4. Perform stemming/lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the spaCy model\n",
    "Can be installed via `python -m spacy download en_core_web_sm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "from googletrans import Translator\n",
    "from lingua import LanguageDetectorBuilder\n",
    "from lingua import IsoCode639_1\n",
    "import nest_asyncio\n",
    "import asyncio\n",
    "from lingua import IsoCode639_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>text</th>\n",
       "      <th>text_id</th>\n",
       "      <th>user</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-10-31</td>\n",
       "      <td>Running a business means juggling countless ad...</td>\n",
       "      <td>2018569761</td>\n",
       "      <td>danielwoodard</td>\n",
       "      <td>1077866112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-10-31</td>\n",
       "      <td>Liz Truss is walking in the lingering shadow o...</td>\n",
       "      <td>2092717718</td>\n",
       "      <td>nelsonjacqueline</td>\n",
       "      <td>1089670430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-10-31</td>\n",
       "      <td>The UK is bracing for war as government buildi...</td>\n",
       "      <td>2059143248</td>\n",
       "      <td>ihooper</td>\n",
       "      <td>1007478642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-10-31</td>\n",
       "      <td>Marrying a second or third cousin once removed...</td>\n",
       "      <td>2008209828</td>\n",
       "      <td>wrightnicholas</td>\n",
       "      <td>1039258480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-10-31</td>\n",
       "      <td>It's truly disgraceful how the Indian National...</td>\n",
       "      <td>2001239278</td>\n",
       "      <td>michael51</td>\n",
       "      <td>1021455936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp                                               text     text_id  \\\n",
       "0 2024-10-31  Running a business means juggling countless ad...  2018569761   \n",
       "1 2024-10-31  Liz Truss is walking in the lingering shadow o...  2092717718   \n",
       "2 2024-10-31  The UK is bracing for war as government buildi...  2059143248   \n",
       "3 2024-10-31  Marrying a second or third cousin once removed...  2008209828   \n",
       "4 2024-10-31  It's truly disgraceful how the Indian National...  2001239278   \n",
       "\n",
       "               user     user_id  \n",
       "0     danielwoodard  1077866112  \n",
       "1  nelsonjacqueline  1089670430  \n",
       "2           ihooper  1007478642  \n",
       "3    wrightnicholas  1039258480  \n",
       "4         michael51  1021455936  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the JSON file\n",
    "df_posts = pd.read_json('../data/dataset.json')\n",
    "df_posts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Info this can take over 30m!!\n",
    "# spacy.prefer_gpu()  # Prefers GPU but doesn't crash if unavailable\n",
    "# nlp = spacy.load(\"en_core_web_trf\")\n",
    "# def extract_entities(text):\n",
    "#     \"\"\"\n",
    "#     Extracts named entities from text using SpaCy's NER model.\n",
    "\n",
    "#     Args:\n",
    "#     text (str): The text from which to extract named entities.\n",
    "\n",
    "#     Returns:\n",
    "#     list: A list of tuples where each tuple contains (entity_text, entity_label).\n",
    "#     \"\"\"\n",
    "#     if not text or pd.isna(text):\n",
    "#         return []  # Return an empty list if text is missing\n",
    "\n",
    "#     # Process text with SpaCy\n",
    "#     doc = nlp(text)\n",
    "\n",
    "#     # Extract entity text and labels\n",
    "#     entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "\n",
    "#     return entities\n",
    "\n",
    "# def preprocess_text(text):\n",
    "#     \"\"\"\n",
    "#     Preprocesses text by removing URLs and emojis while keeping mentions and hashtags intact.\n",
    "\n",
    "#     Args:\n",
    "#     text (str): The original text.\n",
    "\n",
    "#     Returns:\n",
    "#     str: Preprocessed text.\n",
    "#     \"\"\"\n",
    "#     if not text or pd.isna(text):\n",
    "#         return \"\"  # Return empty string if text is missing\n",
    "\n",
    "#     # Remove URLs\n",
    "#     text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text)\n",
    "#     # Remove emojis\n",
    "#     text = emoji.replace_emoji(text, replace=\"\")\n",
    "    \n",
    "#     return text.strip()\n",
    "\n",
    "# # Create a preprocessed text column\n",
    "# df_posts['preprocessed_text'] = df_posts['text'].apply(preprocess_text)\n",
    "\n",
    "# # Apply NER extraction on the preprocessed text\n",
    "# df_posts['entities'] = df_posts['preprocessed_text'].apply(extract_entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for rows with no text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>text</th>\n",
       "      <th>text_id</th>\n",
       "      <th>user</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [timestamp, text, text_id, user, user_id]\n",
       "Index: []"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display rows where 'text' is missing (NaN)\n",
    "missing_text_rows = df_posts[df_posts['text'].isnull()]\n",
    "missing_text_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move hashtags to a new column 'hashtags'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply re.findall() to each row in the 'text' column to extract hashtags\n",
    "df_posts['hashtags'] = df_posts['text'].apply(lambda x: re.findall(r'#\\w+', x) if isinstance(x, str) else [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move mentions to a new column 'mentions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract mentions from the 'text' column, remove the '@' symbol, and create a new column 'mentions'\n",
    "df_posts['mentions'] = df_posts['text'].apply(lambda x: [mention[1:] for mention in re.findall(r'@\\w+', x)] if isinstance(x, str) else [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert text to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posts['text'] = df_posts['text'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove Date from Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([datetime.date(2024, 10, 31)], dtype=object)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All Dates are the same\n",
    "unique_dates = df_posts['timestamp'].dt.date.unique()\n",
    "unique_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>text</th>\n",
       "      <th>text_id</th>\n",
       "      <th>user</th>\n",
       "      <th>user_id</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:00:00</td>\n",
       "      <td>running a business means juggling countless ad...</td>\n",
       "      <td>2018569761</td>\n",
       "      <td>danielwoodard</td>\n",
       "      <td>1077866112</td>\n",
       "      <td>[#HRtech, #businessmanagement]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00:00:00</td>\n",
       "      <td>liz truss is walking in the lingering shadow o...</td>\n",
       "      <td>2092717718</td>\n",
       "      <td>nelsonjacqueline</td>\n",
       "      <td>1089670430</td>\n",
       "      <td>[#politics]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00:00:00</td>\n",
       "      <td>the uk is bracing for war as government buildi...</td>\n",
       "      <td>2059143248</td>\n",
       "      <td>ihooper</td>\n",
       "      <td>1007478642</td>\n",
       "      <td>[#Ukrainewashed, #WarPreparedness]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00:00:00</td>\n",
       "      <td>marrying a second or third cousin once removed...</td>\n",
       "      <td>2008209828</td>\n",
       "      <td>wrightnicholas</td>\n",
       "      <td>1039258480</td>\n",
       "      <td>[#FamilyTree, #GeneticFacts]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00:00:00</td>\n",
       "      <td>it's truly disgraceful how the indian national...</td>\n",
       "      <td>2001239278</td>\n",
       "      <td>michael51</td>\n",
       "      <td>1021455936</td>\n",
       "      <td>[#RationChorCongress]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  timestamp                                               text     text_id  \\\n",
       "0  00:00:00  running a business means juggling countless ad...  2018569761   \n",
       "1  00:00:00  liz truss is walking in the lingering shadow o...  2092717718   \n",
       "2  00:00:00  the uk is bracing for war as government buildi...  2059143248   \n",
       "3  00:00:00  marrying a second or third cousin once removed...  2008209828   \n",
       "4  00:00:00  it's truly disgraceful how the indian national...  2001239278   \n",
       "\n",
       "               user     user_id                            hashtags mentions  \n",
       "0     danielwoodard  1077866112      [#HRtech, #businessmanagement]       []  \n",
       "1  nelsonjacqueline  1089670430                         [#politics]       []  \n",
       "2           ihooper  1007478642  [#Ukrainewashed, #WarPreparedness]       []  \n",
       "3    wrightnicholas  1039258480        [#FamilyTree, #GeneticFacts]       []  \n",
       "4         michael51  1021455936               [#RationChorCongress]       []  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_posts['timestamp'] = df_posts['timestamp'].dt.time\n",
    "df_posts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove URLs, Mentions, and Special Characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leave apostrophes in here for better lemmatization performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lauritseisengarten/Documents/GitHub/case-study-ul/venv/lib/python3.11/site-packages/pandas/core/generic.py:6299: RuntimeWarning:\n",
      "\n",
      "coroutine 'translate_all_tweets' was never awaited\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emojis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>running a business means juggling countless ad...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>liz truss is walking in the lingering shadow o...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the uk is bracing for war as government buildi...</td>\n",
       "      <td>[🇺🇦]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>marrying a second or third cousin once removed...</td>\n",
       "      <td>[🧬]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it's truly disgraceful how the indian national...</td>\n",
       "      <td>[🤦, ♂]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  emojis\n",
       "0  running a business means juggling countless ad...      []\n",
       "1  liz truss is walking in the lingering shadow o...      []\n",
       "2  the uk is bracing for war as government buildi...    [🇺🇦]\n",
       "3  marrying a second or third cousin once removed...     [🧬]\n",
       "4  it's truly disgraceful how the indian national...  [🤦, ♂]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pre-compile regex patterns\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "    u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "    u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "    u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "    u\"\\U0001F1E0-\\U0001F1FF\"  # flags\n",
    "    u\"\\U00002700-\\U000027BF\"  # dingbats\n",
    "    u\"\\U0001F900-\\U0001F9FF\"  # supplemental symbols and pictographs\n",
    "    u\"\\U00002600-\\U000026FF\"  # miscellaneous symbols\n",
    "    u\"\\U00002B50-\\U00002B55\"  # stars\n",
    "    \"]+\", flags=re.UNICODE)\n",
    "\n",
    "url_pattern = re.compile(r'http\\S+|www\\S+|https\\S+')  # Removes URLs\n",
    "mention_pattern = re.compile(r'@\\w+')  # Removes mentions\n",
    "punctuation_pattern = re.compile(r\"[^\\w\\s'’]\")  # Removes punctuation but keeps apostrophes\n",
    "number_pattern = re.compile(r'\\d+')  # Removes numbers\n",
    "whitespace_pattern = re.compile(r'\\s+')  # Removes excessive whitespace\n",
    "hashtag_pattern = re.compile(r'#\\w+')  # Removes hashtags and all text after them\n",
    "\n",
    "# Removes spaces between letters in a single word\n",
    "letter_spacing_pattern = re.compile(r'(\\b\\w)(?:\\s+)(\\w\\b)')\n",
    "\n",
    "# List of terms to remove\n",
    "remove_tw_terms = [\"cc\", \"cx\", \"ct\", \"dm\", \"ht\", \"mt\", \"prt\", \"rt\", \"followback\", \"follow back\", \"fb\", \"retweet\", \"retweets\"]\n",
    "\n",
    "# Compile regex to match terms (case insensitive and whole word)\n",
    "remove_terms_pattern = re.compile(r'\\b(' + '|'.join(remove_tw_terms) + r')\\b')\n",
    "\n",
    "# Updated regex for matching spaced-out letters (e.g., \"s h a r e\")\n",
    "letter_spacing_pattern = re.compile(r'(\\b(?:\\w\\s)+\\w\\b)')\n",
    "\n",
    "# Function to merge spaced-out letters\n",
    "def merge_spaced_letters(match):\n",
    "    # Remove spaces within the matched group\n",
    "    return match.group(0).replace(' ', '')\n",
    "\n",
    "def normalize_full_width(text):\n",
    "    # Convert full-width characters to half-width\n",
    "    return ''.join(\n",
    "        chr(ord(char) - 0xFEE0) if 0xFF01 <= ord(char) <= 0xFF5E else char\n",
    "        for char in text\n",
    "    )\n",
    "\n",
    "# Updated preprocessing function\n",
    "def preprocess_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\", []  # Handle missing values gracefully\n",
    "    \n",
    "    # Normalize full-width characters\n",
    "    text = normalize_full_width(text)\n",
    "\n",
    "    # Extract emojis\n",
    "    emojis = emoji_pattern.findall(text)  # List of emojis\n",
    "\n",
    "    # Remove hashtags and text following them\n",
    "    text = hashtag_pattern.sub('', text)\n",
    "\n",
    "    # Remove emojis, URLs, mentions, punctuation, and numbers\n",
    "    text = emoji_pattern.sub('', text)  # Remove emojis\n",
    "    text = url_pattern.sub('', text)  # Remove URLs\n",
    "    text = mention_pattern.sub('', text)  # Remove mentions\n",
    "    text = punctuation_pattern.sub('', text)  # Remove punctuation\n",
    "    text = number_pattern.sub('', text)  # Remove numbers\n",
    "\n",
    "    # Remove specific terms (CC, CX, CT, DM, etc.)\n",
    "    text = remove_terms_pattern.sub('', text)\n",
    "\n",
    "    # Normalize letter spacing (e.g., \"s h a r e\" -> \"share\")\n",
    "    text = letter_spacing_pattern.sub(merge_spaced_letters, text)\n",
    "\n",
    "    # Remove excessive whitespace and trim\n",
    "    text = whitespace_pattern.sub(' ', text).strip()\n",
    "\n",
    "    return text, emojis\n",
    "\n",
    "# Apply preprocessing to create new columns\n",
    "df_posts[['text', 'emojis']] = df_posts['text'].apply(lambda x: pd.Series(preprocess_text(x)))\n",
    "\n",
    "# Display head to check the results\n",
    "df_posts[['text', 'emojis']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total duplicate rows: 40239\n",
      "Unique duplicate tweets: 16405\n"
     ]
    }
   ],
   "source": [
    "# Total duplicate rows\n",
    "total_duplicate_rows = df_posts['text'].duplicated(keep=False).sum()\n",
    "\n",
    "# Number of unique duplicate tweets\n",
    "unique_duplicate_tweets = (df_posts['text'].value_counts() > 1).sum()\n",
    "\n",
    "print(f\"Total duplicate rows: {total_duplicate_rows}\")\n",
    "print(f\"Unique duplicate tweets: {unique_duplicate_tweets}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duplicate stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    16405.000000\n",
      "mean         2.452850\n",
      "std          2.188017\n",
      "min          2.000000\n",
      "25%          2.000000\n",
      "50%          2.000000\n",
      "75%          3.000000\n",
      "max        130.000000\n",
      "Name: count, dtype: float64\n",
      "Number of tweets repeated more than 5 times: 150\n"
     ]
    }
   ],
   "source": [
    "# Get the frequency distribution of tweets\n",
    "frequency_distribution = df_posts['text'].value_counts()\n",
    "\n",
    "# Filter for only duplicates (frequency > 1)\n",
    "duplicate_tweet_frequencies = frequency_distribution[frequency_distribution > 1]\n",
    "\n",
    "# Summary statistics\n",
    "print(duplicate_tweet_frequencies.describe())\n",
    "\n",
    "# How many tweets are repeated more than 5 times?\n",
    "highly_duplicated = (duplicate_tweet_frequencies > 5).sum()\n",
    "print(f\"Number of tweets repeated more than 5 times: {highly_duplicated}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove duplicate tweets only if the same person posted the same tweet (spam) but extract frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Group by 'user' and 'text' and calculate the frequency of each combination\n",
    "df_posts['frequency'] = df_posts.groupby(['user', 'text'])['text'].transform('count')\n",
    "\n",
    "# Step 2: Drop duplicates based on 'user' and 'text' (keeping the first occurrence)\n",
    "df_posts = df_posts.drop_duplicates(subset=['user', 'text'], keep='first').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>text</th>\n",
       "      <th>text_id</th>\n",
       "      <th>user</th>\n",
       "      <th>user_id</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions</th>\n",
       "      <th>emojis</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>00:00:19</td>\n",
       "      <td>wwf no mercy usa variant nintendo n cart only ...</td>\n",
       "      <td>2053226516</td>\n",
       "      <td>reginabarnes</td>\n",
       "      <td>1068051022</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp                                               text     text_id  \\\n",
       "48  00:00:19  wwf no mercy usa variant nintendo n cart only ...  2053226516   \n",
       "\n",
       "            user     user_id hashtags mentions emojis  frequency  \n",
       "48  reginabarnes  1068051022       []       []     []         86  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_posts[df_posts['user'] == 'reginabarnes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indentify language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tweets after filtering: 67405\n",
      "English tweets: 67127\n",
      "Tweets with None language: 278\n",
      "Number of non-English tweets: 1131\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Lingua language detector for all languages\n",
    "detector = LanguageDetectorBuilder.from_all_languages().build()\n",
    "\n",
    "# Function to detect language using Lingua\n",
    "def detect_language_lingua(text):\n",
    "    # Skip tweets with fewer than 3 words\n",
    "    if len(text.split()) < 3:\n",
    "        return None  # Skip these tweets entirely\n",
    "    try:\n",
    "        language = detector.detect_language_of(text)\n",
    "        return language.iso_code_639_1 if language else None  # Return language code or None\n",
    "    except Exception as e:\n",
    "        return None  # Skip on exception\n",
    "\n",
    "# Apply language detection to the 'text' column\n",
    "df_posts['language'] = df_posts['text'].apply(detect_language_lingua)\n",
    "\n",
    "# Convert language column to string representation (e.g., \"EN\" instead of IsoCode639_1.EN)\n",
    "df_posts['language'] = df_posts['language'].apply(lambda lang: lang.name if lang is not None else None)\n",
    "\n",
    "# Filter non-English tweets (ignoring None values)\n",
    "non_english_tweets = df_posts[\n",
    "    (df_posts['language'].notna()) & (df_posts['language'] != 'EN')\n",
    "]\n",
    "\n",
    "# Filter to keep English tweets AND tweets with None language\n",
    "df_posts = df_posts[\n",
    "    (df_posts['language'] == 'EN') | (df_posts['language'].isna())\n",
    "].copy()\n",
    "\n",
    "# Display diagnostic information\n",
    "print(f\"Total tweets after filtering: {len(df_posts)}\")\n",
    "print(f\"English tweets: {len(df_posts[df_posts['language'] == 'EN'])}\")\n",
    "print(f\"Tweets with None language: {df_posts['language'].isna().sum()}\")\n",
    "print(f\"Number of non-English tweets: {len(non_english_tweets)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the non-English tweets to a CSV file\n",
    "non_english_tweets.to_csv('../output/non_english_tweets.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EN' None]\n"
     ]
    }
   ],
   "source": [
    "print(df_posts['language'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the number of appearances of each Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets per non-english language:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "language\n",
       "PT    522\n",
       "ES    139\n",
       "TL    100\n",
       "SW     40\n",
       "NL     32\n",
       "YO     23\n",
       "TH     22\n",
       "DE     21\n",
       "LA     20\n",
       "ID     20\n",
       "CA     13\n",
       "CY     12\n",
       "DA     11\n",
       "SO     11\n",
       "NB     10\n",
       "AF     10\n",
       "FI     10\n",
       "SQ      9\n",
       "SV      9\n",
       "IT      8\n",
       "FR      8\n",
       "ET      8\n",
       "TS      7\n",
       "NN      6\n",
       "ST      6\n",
       "EU      5\n",
       "XH      5\n",
       "EO      5\n",
       "SN      4\n",
       "TR      4\n",
       "TN      4\n",
       "AR      3\n",
       "KO      3\n",
       "RO      3\n",
       "CS      3\n",
       "HI      2\n",
       "MS      2\n",
       "SK      1\n",
       "LT      1\n",
       "ZU      1\n",
       "BN      1\n",
       "LG      1\n",
       "TA      1\n",
       "JA      1\n",
       "SL      1\n",
       "GA      1\n",
       "MR      1\n",
       "MI      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_counts = non_english_tweets['language'].value_counts()\n",
    "print(\"Number of tweets per non-english language:\")\n",
    "language_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Translate the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets translated: 761\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Initialize translator\n",
    "translator = Translator()\n",
    "\n",
    "# Define languages to translate\n",
    "languages_to_translate = ['PT', 'ES', 'TL']\n",
    "\n",
    "# Filter tweets in the selected languages\n",
    "translated_tweets = non_english_tweets[non_english_tweets['language'].isin(languages_to_translate)].copy()\n",
    "\n",
    "# Function to translate text\n",
    "async def translate_text(text):\n",
    "    try:\n",
    "        result = await translator.translate(text, dest='en')\n",
    "        return result.text\n",
    "    except Exception as e:\n",
    "        return text  # Return original text if translation fails\n",
    "\n",
    "# Async function to translate all tweets\n",
    "async def translate_all_tweets():\n",
    "    translated_tweets['text'] = await asyncio.gather(\n",
    "        *[translate_text(text) for text in translated_tweets['text']]\n",
    "    )\n",
    "    \n",
    "    # Save to CSV\n",
    "    translated_tweets.to_csv('../output/translated_tweets.csv', index=False)\n",
    "    print(f\"Number of tweets translated: {len(translated_tweets)}\")\n",
    "\n",
    "# Get the current event loop\n",
    "loop = asyncio.get_event_loop()\n",
    "\n",
    "# Now you can use asyncio.run()\n",
    "asyncio.run(translate_all_tweets())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>text</th>\n",
       "      <th>text_id</th>\n",
       "      <th>user</th>\n",
       "      <th>user_id</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions</th>\n",
       "      <th>emojis</th>\n",
       "      <th>frequency</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00:00:00</td>\n",
       "      <td>sunshine sunshine sunshine sunshine sunshine s...</td>\n",
       "      <td>2055945627</td>\n",
       "      <td>andrea21</td>\n",
       "      <td>1080017323</td>\n",
       "      <td>[#GoodVibes, #SummerFeels, #EndlessJoy]</td>\n",
       "      <td>[jonathanreynolds]</td>\n",
       "      <td>[☀, ☀, ☀, 💛]</td>\n",
       "      <td>1</td>\n",
       "      <td>TL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>00:02:01</td>\n",
       "      <td>Always vote for the tag and let it decide the ...</td>\n",
       "      <td>2020582097</td>\n",
       "      <td>alvin24</td>\n",
       "      <td>1016376595</td>\n",
       "      <td>[#VoteAriana, #BBMAs2024, #MusicLovers]</td>\n",
       "      <td>[kaitlinlee, randy35]</td>\n",
       "      <td>[😍🔥, 🎤✨]</td>\n",
       "      <td>1</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>00:02:58</td>\n",
       "      <td>Sapang Dalaga MPPS PNP personnel led by Office...</td>\n",
       "      <td>2022877822</td>\n",
       "      <td>leah53</td>\n",
       "      <td>1036411239</td>\n",
       "      <td>[#CommunityEngagement, #PNP, #SafetyFirst]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>TL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>00:03:10</td>\n",
       "      <td>What's the news friends, special surprise is c...</td>\n",
       "      <td>2035146367</td>\n",
       "      <td>vriddle</td>\n",
       "      <td>1061691677</td>\n",
       "      <td>[#KabirSingh]</td>\n",
       "      <td>[uallison, wcarter, matthew45, wayne59]</td>\n",
       "      <td>[🎉]</td>\n",
       "      <td>1</td>\n",
       "      <td>TL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>00:03:16</td>\n",
       "      <td>although I can no longer vote on other platfor...</td>\n",
       "      <td>2075428124</td>\n",
       "      <td>amyweaver</td>\n",
       "      <td>1020527420</td>\n",
       "      <td>[#VMAs, #BLACKPINK, #GirlPower]</td>\n",
       "      <td>[lauren57]</td>\n",
       "      <td>[💖, 🎉✨]</td>\n",
       "      <td>1</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68269</th>\n",
       "      <td>23:52:50</td>\n",
       "      <td>triple vibes i am voting for bts for top socia...</td>\n",
       "      <td>2016655749</td>\n",
       "      <td>kbrown</td>\n",
       "      <td>1029276895</td>\n",
       "      <td>[#BBMAs, #BTSBBMAs]</td>\n",
       "      <td>[dsmith]</td>\n",
       "      <td>[✨, ❤]</td>\n",
       "      <td>1</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68273</th>\n",
       "      <td>23:52:56</td>\n",
       "      <td>thousand and jungkook will sing on your birthd...</td>\n",
       "      <td>2076418073</td>\n",
       "      <td>james39</td>\n",
       "      <td>1039700711</td>\n",
       "      <td>[#AMAs, #BTS, #ArmyForever]</td>\n",
       "      <td>[jocelynjones]</td>\n",
       "      <td>[🎉, 💜]</td>\n",
       "      <td>1</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68387</th>\n",
       "      <td>23:56:04</td>\n",
       "      <td>If this tweet reaches Jungkook he will do a da...</td>\n",
       "      <td>2029973523</td>\n",
       "      <td>erikwhite</td>\n",
       "      <td>1087487919</td>\n",
       "      <td>[#AMAs, #BTSAMAs]</td>\n",
       "      <td>[yschwartz, yhawkins]</td>\n",
       "      <td>[💜]</td>\n",
       "      <td>1</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68451</th>\n",
       "      <td>23:57:38</td>\n",
       "      <td>Voting is on, vote for the hashtag and listen ...</td>\n",
       "      <td>2005853368</td>\n",
       "      <td>kellygabriel</td>\n",
       "      <td>1053558936</td>\n",
       "      <td>[#StrayKids, #MAMAs2023]</td>\n",
       "      <td>[brauncarrie, renee24]</td>\n",
       "      <td>[💖🔥]</td>\n",
       "      <td>1</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68514</th>\n",
       "      <td>23:59:26</td>\n",
       "      <td>What is this, Katy Perry has retired, she beli...</td>\n",
       "      <td>2056616801</td>\n",
       "      <td>kevin71</td>\n",
       "      <td>1044910984</td>\n",
       "      <td>[#AMAs, #KatyPerryForever]</td>\n",
       "      <td>[jessica77, ginakirk]</td>\n",
       "      <td>[🌟, 💖✨]</td>\n",
       "      <td>1</td>\n",
       "      <td>PT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>761 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      timestamp                                               text  \\\n",
       "8      00:00:00  sunshine sunshine sunshine sunshine sunshine s...   \n",
       "187    00:02:01  Always vote for the tag and let it decide the ...   \n",
       "240    00:02:58  Sapang Dalaga MPPS PNP personnel led by Office...   \n",
       "252    00:03:10  What's the news friends, special surprise is c...   \n",
       "256    00:03:16  although I can no longer vote on other platfor...   \n",
       "...         ...                                                ...   \n",
       "68269  23:52:50  triple vibes i am voting for bts for top socia...   \n",
       "68273  23:52:56  thousand and jungkook will sing on your birthd...   \n",
       "68387  23:56:04  If this tweet reaches Jungkook he will do a da...   \n",
       "68451  23:57:38  Voting is on, vote for the hashtag and listen ...   \n",
       "68514  23:59:26  What is this, Katy Perry has retired, she beli...   \n",
       "\n",
       "          text_id          user     user_id  \\\n",
       "8      2055945627      andrea21  1080017323   \n",
       "187    2020582097       alvin24  1016376595   \n",
       "240    2022877822        leah53  1036411239   \n",
       "252    2035146367       vriddle  1061691677   \n",
       "256    2075428124     amyweaver  1020527420   \n",
       "...           ...           ...         ...   \n",
       "68269  2016655749        kbrown  1029276895   \n",
       "68273  2076418073       james39  1039700711   \n",
       "68387  2029973523     erikwhite  1087487919   \n",
       "68451  2005853368  kellygabriel  1053558936   \n",
       "68514  2056616801       kevin71  1044910984   \n",
       "\n",
       "                                         hashtags  \\\n",
       "8         [#GoodVibes, #SummerFeels, #EndlessJoy]   \n",
       "187       [#VoteAriana, #BBMAs2024, #MusicLovers]   \n",
       "240    [#CommunityEngagement, #PNP, #SafetyFirst]   \n",
       "252                                 [#KabirSingh]   \n",
       "256               [#VMAs, #BLACKPINK, #GirlPower]   \n",
       "...                                           ...   \n",
       "68269                         [#BBMAs, #BTSBBMAs]   \n",
       "68273                 [#AMAs, #BTS, #ArmyForever]   \n",
       "68387                           [#AMAs, #BTSAMAs]   \n",
       "68451                    [#StrayKids, #MAMAs2023]   \n",
       "68514                  [#AMAs, #KatyPerryForever]   \n",
       "\n",
       "                                      mentions        emojis  frequency  \\\n",
       "8                           [jonathanreynolds]  [☀, ☀, ☀, 💛]          1   \n",
       "187                      [kaitlinlee, randy35]      [😍🔥, 🎤✨]          1   \n",
       "240                                         []            []          1   \n",
       "252    [uallison, wcarter, matthew45, wayne59]           [🎉]          1   \n",
       "256                                 [lauren57]       [💖, 🎉✨]          1   \n",
       "...                                        ...           ...        ...   \n",
       "68269                                 [dsmith]        [✨, ❤]          1   \n",
       "68273                           [jocelynjones]        [🎉, 💜]          1   \n",
       "68387                    [yschwartz, yhawkins]           [💜]          1   \n",
       "68451                   [brauncarrie, renee24]          [💖🔥]          1   \n",
       "68514                    [jessica77, ginakirk]       [🌟, 💖✨]          1   \n",
       "\n",
       "      language  \n",
       "8           TL  \n",
       "187         PT  \n",
       "240         TL  \n",
       "252         TL  \n",
       "256         ES  \n",
       "...        ...  \n",
       "68269       PT  \n",
       "68273       PT  \n",
       "68387       PT  \n",
       "68451       PT  \n",
       "68514       PT  \n",
       "\n",
       "[761 rows x 10 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append translated tweets to english tweets dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final number of tweets: 68166\n"
     ]
    }
   ],
   "source": [
    "df_posts = pd.concat([df_posts, translated_tweets], ignore_index=True)\n",
    "\n",
    "print(f\"Final number of tweets: {len(df_posts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export for Topic Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posts.to_csv('../output/export_for_topic_classification.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load en_core_web_sm for spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use lemmatization since stemming can lead to less accurate results (even non-words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Info this takes about 4.5m!!\n",
    "df_posts['text'] = df_posts['text'].apply(\n",
    "        lambda text: ' '.join([token.lemma_ for token in nlp(text)])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create output for sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posts.to_csv('../output/preprocessed_for_SA.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posts['text'] = df_posts['text'].fillna(\"\").apply(\n",
    "    lambda text: ' '.join([token.text for token in nlp.make_doc(text) if not token.is_stop])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Apostrophes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posts['text'] = df_posts['text'].str.replace(r\"[’']\", \"\", regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check again for empty rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>text</th>\n",
       "      <th>text_id</th>\n",
       "      <th>user</th>\n",
       "      <th>user_id</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions</th>\n",
       "      <th>emojis</th>\n",
       "      <th>frequency</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [timestamp, text, text_id, user, user_id, hashtags, mentions, emojis, frequency, language]\n",
       "Index: []"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display rows where 'text' is missing (NaN)\n",
    "missing_text_rows = df_posts[df_posts['text'].isnull()]\n",
    "missing_text_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the output to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posts.to_csv('../output/preprocessed.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
