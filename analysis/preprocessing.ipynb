{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "1. Convert text to lowercase \n",
    "2. Remove URLs, mentions, and special characters (besides hashtags and emojis)\n",
    "3. Remove stop words\n",
    "4. Perform stemming/lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the spaCy model\n",
    "Can be installed via `python -m spacy download en_core_web_sm`\n",
    "\n",
    "Download Pre-Trained-Language Model:\n",
    "\n",
    "Can be installed via wget: `wget -P /path/to/your/directory https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin`\n",
    "\n",
    "or via curl: `curl -O https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>text</th>\n",
       "      <th>text_id</th>\n",
       "      <th>user</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-10-31</td>\n",
       "      <td>Running a business means juggling countless ad...</td>\n",
       "      <td>2018569761</td>\n",
       "      <td>danielwoodard</td>\n",
       "      <td>1077866112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-10-31</td>\n",
       "      <td>Liz Truss is walking in the lingering shadow o...</td>\n",
       "      <td>2092717718</td>\n",
       "      <td>nelsonjacqueline</td>\n",
       "      <td>1089670430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-10-31</td>\n",
       "      <td>The UK is bracing for war as government buildi...</td>\n",
       "      <td>2059143248</td>\n",
       "      <td>ihooper</td>\n",
       "      <td>1007478642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-10-31</td>\n",
       "      <td>Marrying a second or third cousin once removed...</td>\n",
       "      <td>2008209828</td>\n",
       "      <td>wrightnicholas</td>\n",
       "      <td>1039258480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-10-31</td>\n",
       "      <td>It's truly disgraceful how the Indian National...</td>\n",
       "      <td>2001239278</td>\n",
       "      <td>michael51</td>\n",
       "      <td>1021455936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp                                               text     text_id  \\\n",
       "0 2024-10-31  Running a business means juggling countless ad...  2018569761   \n",
       "1 2024-10-31  Liz Truss is walking in the lingering shadow o...  2092717718   \n",
       "2 2024-10-31  The UK is bracing for war as government buildi...  2059143248   \n",
       "3 2024-10-31  Marrying a second or third cousin once removed...  2008209828   \n",
       "4 2024-10-31  It's truly disgraceful how the Indian National...  2001239278   \n",
       "\n",
       "               user     user_id  \n",
       "0     danielwoodard  1077866112  \n",
       "1  nelsonjacqueline  1089670430  \n",
       "2           ihooper  1007478642  \n",
       "3    wrightnicholas  1039258480  \n",
       "4         michael51  1021455936  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the JSON file\n",
    "df_posts = pd.read_json('../data/dataset.json')\n",
    "df_posts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Info this can take over 30m!!\n",
    "# spacy.prefer_gpu()  # Prefers GPU but doesn't crash if unavailable\n",
    "# nlp = spacy.load(\"en_core_web_trf\")\n",
    "# def extract_entities(text):\n",
    "#     \"\"\"\n",
    "#     Extracts named entities from text using SpaCy's NER model.\n",
    "\n",
    "#     Args:\n",
    "#     text (str): The text from which to extract named entities.\n",
    "\n",
    "#     Returns:\n",
    "#     list: A list of tuples where each tuple contains (entity_text, entity_label).\n",
    "#     \"\"\"\n",
    "#     if not text or pd.isna(text):\n",
    "#         return []  # Return an empty list if text is missing\n",
    "\n",
    "#     # Process text with SpaCy\n",
    "#     doc = nlp(text)\n",
    "\n",
    "#     # Extract entity text and labels\n",
    "#     entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "\n",
    "#     return entities\n",
    "\n",
    "# def preprocess_text(text):\n",
    "#     \"\"\"\n",
    "#     Preprocesses text by removing URLs and emojis while keeping mentions and hashtags intact.\n",
    "\n",
    "#     Args:\n",
    "#     text (str): The original text.\n",
    "\n",
    "#     Returns:\n",
    "#     str: Preprocessed text.\n",
    "#     \"\"\"\n",
    "#     if not text or pd.isna(text):\n",
    "#         return \"\"  # Return empty string if text is missing\n",
    "\n",
    "#     # Remove URLs\n",
    "#     text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text)\n",
    "#     # Remove emojis\n",
    "#     text = emoji.replace_emoji(text, replace=\"\")\n",
    "    \n",
    "#     return text.strip()\n",
    "\n",
    "# # Create a preprocessed text column\n",
    "# df_posts['preprocessed_text'] = df_posts['text'].apply(preprocess_text)\n",
    "\n",
    "# # Apply NER extraction on the preprocessed text\n",
    "# df_posts['entities'] = df_posts['preprocessed_text'].apply(extract_entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for rows with no text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>text</th>\n",
       "      <th>text_id</th>\n",
       "      <th>user</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [timestamp, text, text_id, user, user_id]\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display rows where 'text' is missing (NaN)\n",
    "missing_text_rows = df_posts[df_posts['text'].isnull()]\n",
    "missing_text_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move hashtags to a new column 'hashtags'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply re.findall() to each row in the 'text' column to extract hashtags\n",
    "df_posts['hashtags'] = df_posts['text'].apply(lambda x: re.findall(r'#\\w+', x) if isinstance(x, str) else [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move mentions to a new column 'mentions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract mentions from the 'text' column, remove the '@' symbol, and create a new column 'mentions'\n",
    "df_posts['mentions'] = df_posts['text'].apply(lambda x: [mention[1:] for mention in re.findall(r'@\\w+', x)] if isinstance(x, str) else [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert text to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posts['text'] = df_posts['text'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove Date from Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Dates are the same\n",
    "unique_dates = df_posts['timestamp'].dt.date.unique()\n",
    "unique_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posts['timestamp'] = df_posts['timestamp'].dt.time\n",
    "df_posts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove URLs, Mentions, and Special Characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leave apostrophes in here for better lemmatization performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Pre-compile regex patterns\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "    u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "    u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "    u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "    u\"\\U0001F1E0-\\U0001F1FF\"  # flags\n",
    "    u\"\\U00002700-\\U000027BF\"  # dingbats\n",
    "    u\"\\U0001F900-\\U0001F9FF\"  # supplemental symbols and pictographs\n",
    "    u\"\\U00002600-\\U000026FF\"  # miscellaneous symbols\n",
    "    u\"\\U00002B50-\\U00002B55\"  # stars\n",
    "    \"]+\", flags=re.UNICODE)\n",
    "\n",
    "url_pattern = re.compile(r'http\\S+|www\\S+|https\\S+')\n",
    "mention_pattern = re.compile(r'@\\w+')  # Removes mentions\n",
    "punctuation_pattern = re.compile(r\"[^\\w\\s'’]\")  # Removes punctuation but keeps apostrophes\n",
    "number_pattern = re.compile(r'\\d+')  # Removes numbers\n",
    "whitespace_pattern = re.compile(r'\\s+')  # Removes excessive whitespace\n",
    "hashtag_pattern = re.compile(r'#\\w+')  # Removes hashtags and all text after them\n",
    "\n",
    "# List of terms to remove\n",
    "remove_tw_terms = [\"cc\", \"cx\", \"ct\", \"dm\", \"ht\", \"mt\", \"prt\", \"rt\", \"followback\", \"follow back\", \"fb\", \"retweet\", \"retweets\"]\n",
    "\n",
    "# Compile regex to match terms (case insensitive and whole word)\n",
    "remove_terms_pattern = re.compile(r'\\b(' + '|'.join(remove_tw_terms) + r')\\b')\n",
    "\n",
    "# Optimized function\n",
    "def preprocess_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\", []  # Handle missing values gracefully\n",
    "\n",
    "    # Extract emojis\n",
    "    emojis = emoji_pattern.findall(text)  # List of emojis\n",
    "\n",
    "    # Remove hashtags and text following them\n",
    "    text = hashtag_pattern.sub('', text)\n",
    "\n",
    "    # Remove emojis, URLs, mentions, punctuation, and numbers\n",
    "    text = emoji_pattern.sub('', text)  # Remove emojis\n",
    "    text = url_pattern.sub('', text)  # Remove URLs\n",
    "    text = mention_pattern.sub('', text)  # Remove mentions\n",
    "    text = punctuation_pattern.sub('', text)  # Remove punctuation\n",
    "    text = number_pattern.sub('', text)  # Remove numbers\n",
    "\n",
    "    # Remove specific terms (CC, CX, CT, DM, etc.)\n",
    "    text = remove_terms_pattern.sub('', text)\n",
    "\n",
    "    # Remove excessive whitespace and trim\n",
    "    text = whitespace_pattern.sub(' ', text).strip()\n",
    "\n",
    "    return text, emojis\n",
    "\n",
    "# Apply preprocessing to create new columns\n",
    "df_posts[['text', 'emojis']] = df_posts['text'].apply(lambda x: pd.Series(preprocess_text(x)))\n",
    "\n",
    "# Display head to check the results\n",
    "df_posts[['text', 'emojis']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posts.to_csv('../output/testing.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total duplicate rows\n",
    "total_duplicate_rows = df_posts['text'].duplicated(keep=False).sum()\n",
    "\n",
    "# Number of unique duplicate tweets\n",
    "unique_duplicate_tweets = (df_posts['text'].value_counts() > 1).sum()\n",
    "\n",
    "print(f\"Total duplicate rows: {total_duplicate_rows}\")\n",
    "print(f\"Unique duplicate tweets: {unique_duplicate_tweets}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duplicate stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the frequency distribution of tweets\n",
    "frequency_distribution = df_posts['text'].value_counts()\n",
    "\n",
    "# Filter for only duplicates (frequency > 1)\n",
    "duplicate_tweet_frequencies = frequency_distribution[frequency_distribution > 1]\n",
    "\n",
    "# Summary statistics\n",
    "print(duplicate_tweet_frequencies.describe())\n",
    "\n",
    "# How many tweets are repeated more than 5 times?\n",
    "highly_duplicated = (duplicate_tweet_frequencies > 5).sum()\n",
    "print(f\"Number of tweets repeated more than 5 times: {highly_duplicated}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove duplicate tweets but extract count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posts['frequency'] = df_posts['text'].map(df_posts['text'].value_counts())\n",
    "\n",
    "df_posts = df_posts.drop_duplicates(subset='text', keep='first').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_posts[['text', 'frequency']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posts[df_posts['user'] == 'reginabarnes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_twets = df_posts[df_posts['user'] == 'reginabarnes']  # Filter rows for 'reginabarnes'\n",
    "rb_twets.to_csv('../output/rb_tweets.csv', index=False)  # Save to CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indentify language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained language identification model\n",
    "model = fasttext.load_model('lid.176.bin')\n",
    "\n",
    "# Function to detect language using FastText\n",
    "def detect_language_fasttext(text, threshold=0.9):\n",
    "    if pd.isna(text) or not text.strip():\n",
    "        return \"unknown\"  # Handle empty or missing text\n",
    "    try:\n",
    "        predictions = model.predict(text)  # Predict the language\n",
    "        lang_code = predictions[0][0].replace(\"__label__\", \"\")  # Extract language code\n",
    "        return lang_code\n",
    "    except Exception as e:\n",
    "        return \"unknown\"\n",
    "\n",
    "# Apply language detection to the 'text' column\n",
    "df_posts['language'] = df_posts['text'].apply(detect_language_fasttext)\n",
    "\n",
    "# Filter non-English tweets\n",
    "non_english_tweets = df_posts[df_posts['language'] != 'en']\n",
    "\n",
    "# Display the number of non-English tweets and a sample\n",
    "print(f\"Number of non-English tweets: {len(non_english_tweets)}\")\n",
    "print(non_english_tweets[['text', 'language']])\n",
    "\n",
    "non_english_tweets.to_csv('../output/non_english_tweets.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load en_core_web_sm for spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use lemmatization since stemming can lead to less accurate results (even non-words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Info this takes about 2.5m!!\n",
    "df_posts['text'] = df_posts['text'].apply(\n",
    "        lambda text: ' '.join([token.lemma_ for token in nlp(text)])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create output for sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posts.to_csv('../output/preprocessed_for_SA.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posts['text'] = df_posts['text'].fillna(\"\").apply(\n",
    "    lambda text: ' '.join([token.text for token in nlp.make_doc(text) if not token.is_stop])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Apostrophes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posts['text'] = df_posts['text'].str.replace(r\"[’']\", \"\", regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check again for empty rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display rows where 'text' is missing (NaN)\n",
    "missing_text_rows = df_posts[df_posts['text'].isnull()]\n",
    "missing_text_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the output to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posts.to_csv('../output/preprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>text</th>\n",
       "      <th>text_id</th>\n",
       "      <th>user</th>\n",
       "      <th>user_id</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>2024-10-31 00:03:26</td>\n",
       "      <td>Check out this article for a rapid technique t...</td>\n",
       "      <td>2042924876</td>\n",
       "      <td>wadekaren</td>\n",
       "      <td>1059374550</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4715</th>\n",
       "      <td>2024-10-31 01:20:49</td>\n",
       "      <td>Regain your health and well-being by shedding ...</td>\n",
       "      <td>2086330600</td>\n",
       "      <td>annflores</td>\n",
       "      <td>1031522730</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4825</th>\n",
       "      <td>2024-10-31 01:23:13</td>\n",
       "      <td>Unlock the secrets to shedding fat successfull...</td>\n",
       "      <td>2097208346</td>\n",
       "      <td>annflores</td>\n",
       "      <td>1031522730</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4961</th>\n",
       "      <td>2024-10-31 01:25:26</td>\n",
       "      <td>Discover the secrets of successful home busine...</td>\n",
       "      <td>2063586212</td>\n",
       "      <td>annflores</td>\n",
       "      <td>1031522730</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5021</th>\n",
       "      <td>2024-10-31 01:26:32</td>\n",
       "      <td>Ready to take your fitness to the next level? ...</td>\n",
       "      <td>2082803004</td>\n",
       "      <td>annflores</td>\n",
       "      <td>1031522730</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5083</th>\n",
       "      <td>2024-10-31 01:27:40</td>\n",
       "      <td>Struggling to get rid of cellulite and get bac...</td>\n",
       "      <td>2028891694</td>\n",
       "      <td>annflores</td>\n",
       "      <td>1031522730</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8029</th>\n",
       "      <td>2024-10-31 02:22:05</td>\n",
       "      <td>Don't put your health at risk by ignoring unwa...</td>\n",
       "      <td>2073970213</td>\n",
       "      <td>annflores</td>\n",
       "      <td>1031522730</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8030</th>\n",
       "      <td>2024-10-31 02:22:05</td>\n",
       "      <td>Revitalize your work-at-home business with thi...</td>\n",
       "      <td>2065031382</td>\n",
       "      <td>annflores</td>\n",
       "      <td>1031522730</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8407</th>\n",
       "      <td>2024-10-31 02:28:59</td>\n",
       "      <td>Looking to shed some extra pounds and improve ...</td>\n",
       "      <td>2083022452</td>\n",
       "      <td>annflores</td>\n",
       "      <td>1031522730</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9802</th>\n",
       "      <td>2024-10-31 02:55:20</td>\n",
       "      <td>Don't put your health at risk by storing exces...</td>\n",
       "      <td>2084074601</td>\n",
       "      <td>annflores</td>\n",
       "      <td>1031522730</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11215</th>\n",
       "      <td>2024-10-31 03:19:42</td>\n",
       "      <td>Discover the keys to internet business success...</td>\n",
       "      <td>2038194330</td>\n",
       "      <td>annflores</td>\n",
       "      <td>1031522730</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11400</th>\n",
       "      <td>2024-10-31 03:22:49</td>\n",
       "      <td>Discover a rapid technique to enhance your hea...</td>\n",
       "      <td>2091429276</td>\n",
       "      <td>annflores</td>\n",
       "      <td>1031522730</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11555</th>\n",
       "      <td>2024-10-31 03:25:11</td>\n",
       "      <td>Discover the secret to shedding excess fat and...</td>\n",
       "      <td>2041453102</td>\n",
       "      <td>annflores</td>\n",
       "      <td>1031522730</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11618</th>\n",
       "      <td>2024-10-31 03:26:09</td>\n",
       "      <td>Increase your website traffic for your home bu...</td>\n",
       "      <td>2029789550</td>\n",
       "      <td>annflores</td>\n",
       "      <td>1031522730</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12930</th>\n",
       "      <td>2024-10-31 03:47:29</td>\n",
       "      <td>Losing weight starts with regaining your healt...</td>\n",
       "      <td>2093495443</td>\n",
       "      <td>rwood</td>\n",
       "      <td>1073144224</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12949</th>\n",
       "      <td>2024-10-31 03:47:46</td>\n",
       "      <td>Struggling to lose body fat? Try this effectiv...</td>\n",
       "      <td>2074758996</td>\n",
       "      <td>rwood</td>\n",
       "      <td>1073144224</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13004</th>\n",
       "      <td>2024-10-31 03:48:54</td>\n",
       "      <td>Be mindful of your diet and exercise to stay h...</td>\n",
       "      <td>2026117730</td>\n",
       "      <td>rwood</td>\n",
       "      <td>1073144224</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13023</th>\n",
       "      <td>2024-10-31 03:49:21</td>\n",
       "      <td>Excess body fat can pose serious health risks,...</td>\n",
       "      <td>2067893099</td>\n",
       "      <td>rwood</td>\n",
       "      <td>1073144224</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13040</th>\n",
       "      <td>2024-10-31 03:49:41</td>\n",
       "      <td>Reclaim your health and shed those unwanted fa...</td>\n",
       "      <td>2032008673</td>\n",
       "      <td>rwood</td>\n",
       "      <td>1073144224</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13053</th>\n",
       "      <td>2024-10-31 03:50:00</td>\n",
       "      <td>Looking to attract more clients for your home ...</td>\n",
       "      <td>2025316449</td>\n",
       "      <td>rwood</td>\n",
       "      <td>1073144224</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13079</th>\n",
       "      <td>2024-10-31 03:50:21</td>\n",
       "      <td>Looking for ways to boost your home business? ...</td>\n",
       "      <td>2016126837</td>\n",
       "      <td>rwood</td>\n",
       "      <td>1073144224</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13107</th>\n",
       "      <td>2024-10-31 03:50:49</td>\n",
       "      <td>Uncover the key to unlocking your internet bus...</td>\n",
       "      <td>2093673646</td>\n",
       "      <td>rwood</td>\n",
       "      <td>1073144224</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13130</th>\n",
       "      <td>2024-10-31 03:51:08</td>\n",
       "      <td>Uncover the key strategies to boost your onlin...</td>\n",
       "      <td>2057203385</td>\n",
       "      <td>rwood</td>\n",
       "      <td>1073144224</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13143</th>\n",
       "      <td>2024-10-31 03:51:22</td>\n",
       "      <td>Discover the best techniques to improve your h...</td>\n",
       "      <td>2095382499</td>\n",
       "      <td>rwood</td>\n",
       "      <td>1073144224</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13169</th>\n",
       "      <td>2024-10-31 03:51:36</td>\n",
       "      <td>Losing fat and getting in shape has never been...</td>\n",
       "      <td>2085589565</td>\n",
       "      <td>rwood</td>\n",
       "      <td>1073144224</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13185</th>\n",
       "      <td>2024-10-31 03:51:51</td>\n",
       "      <td>Discover the hidden secret to weight loss that...</td>\n",
       "      <td>2026022630</td>\n",
       "      <td>rwood</td>\n",
       "      <td>1073144224</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41133</th>\n",
       "      <td>2024-10-31 17:40:06</td>\n",
       "      <td>Bring comfort dogs to every university lecture...</td>\n",
       "      <td>2028300685</td>\n",
       "      <td>douglassteve</td>\n",
       "      <td>1056029196</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                timestamp                                               text  \\\n",
       "261   2024-10-31 00:03:26  Check out this article for a rapid technique t...   \n",
       "4715  2024-10-31 01:20:49  Regain your health and well-being by shedding ...   \n",
       "4825  2024-10-31 01:23:13  Unlock the secrets to shedding fat successfull...   \n",
       "4961  2024-10-31 01:25:26  Discover the secrets of successful home busine...   \n",
       "5021  2024-10-31 01:26:32  Ready to take your fitness to the next level? ...   \n",
       "5083  2024-10-31 01:27:40  Struggling to get rid of cellulite and get bac...   \n",
       "8029  2024-10-31 02:22:05  Don't put your health at risk by ignoring unwa...   \n",
       "8030  2024-10-31 02:22:05  Revitalize your work-at-home business with thi...   \n",
       "8407  2024-10-31 02:28:59  Looking to shed some extra pounds and improve ...   \n",
       "9802  2024-10-31 02:55:20  Don't put your health at risk by storing exces...   \n",
       "11215 2024-10-31 03:19:42  Discover the keys to internet business success...   \n",
       "11400 2024-10-31 03:22:49  Discover a rapid technique to enhance your hea...   \n",
       "11555 2024-10-31 03:25:11  Discover the secret to shedding excess fat and...   \n",
       "11618 2024-10-31 03:26:09  Increase your website traffic for your home bu...   \n",
       "12930 2024-10-31 03:47:29  Losing weight starts with regaining your healt...   \n",
       "12949 2024-10-31 03:47:46  Struggling to lose body fat? Try this effectiv...   \n",
       "13004 2024-10-31 03:48:54  Be mindful of your diet and exercise to stay h...   \n",
       "13023 2024-10-31 03:49:21  Excess body fat can pose serious health risks,...   \n",
       "13040 2024-10-31 03:49:41  Reclaim your health and shed those unwanted fa...   \n",
       "13053 2024-10-31 03:50:00  Looking to attract more clients for your home ...   \n",
       "13079 2024-10-31 03:50:21  Looking for ways to boost your home business? ...   \n",
       "13107 2024-10-31 03:50:49  Uncover the key to unlocking your internet bus...   \n",
       "13130 2024-10-31 03:51:08  Uncover the key strategies to boost your onlin...   \n",
       "13143 2024-10-31 03:51:22  Discover the best techniques to improve your h...   \n",
       "13169 2024-10-31 03:51:36  Losing fat and getting in shape has never been...   \n",
       "13185 2024-10-31 03:51:51  Discover the hidden secret to weight loss that...   \n",
       "41133 2024-10-31 17:40:06  Bring comfort dogs to every university lecture...   \n",
       "\n",
       "          text_id          user     user_id  frequency  \n",
       "261    2042924876     wadekaren  1059374550          8  \n",
       "4715   2086330600     annflores  1031522730          8  \n",
       "4825   2097208346     annflores  1031522730          8  \n",
       "4961   2063586212     annflores  1031522730          8  \n",
       "5021   2082803004     annflores  1031522730          8  \n",
       "5083   2028891694     annflores  1031522730          8  \n",
       "8029   2073970213     annflores  1031522730          8  \n",
       "8030   2065031382     annflores  1031522730          8  \n",
       "8407   2083022452     annflores  1031522730          8  \n",
       "9802   2084074601     annflores  1031522730          8  \n",
       "11215  2038194330     annflores  1031522730          8  \n",
       "11400  2091429276     annflores  1031522730          8  \n",
       "11555  2041453102     annflores  1031522730          8  \n",
       "11618  2029789550     annflores  1031522730          8  \n",
       "12930  2093495443         rwood  1073144224          8  \n",
       "12949  2074758996         rwood  1073144224          8  \n",
       "13004  2026117730         rwood  1073144224          8  \n",
       "13023  2067893099         rwood  1073144224          8  \n",
       "13040  2032008673         rwood  1073144224          8  \n",
       "13053  2025316449         rwood  1073144224          8  \n",
       "13079  2016126837         rwood  1073144224          8  \n",
       "13107  2093673646         rwood  1073144224          8  \n",
       "13130  2057203385         rwood  1073144224          8  \n",
       "13143  2095382499         rwood  1073144224          8  \n",
       "13169  2085589565         rwood  1073144224          8  \n",
       "13185  2026022630         rwood  1073144224          8  \n",
       "41133  2028300685  douglassteve  1056029196        130  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_posts[df_posts['frequency'] > 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47       WWF No Mercy USA-1 VARIANT Nintendo 64 N64 Car...\n",
      "653      WWF No Mercy USA-1 VARIANT Nintendo 64 N64 Car...\n",
      "1277     WWF No Mercy USA-1 VARIANT Nintendo 64 N64 Car...\n",
      "1855     WWF No Mercy USA-1 VARIANT Nintendo 64 N64 Car...\n",
      "6266     WWF No Mercy USA-1 VARIANT Nintendo 64 N64 Car...\n",
      "                               ...                        \n",
      "46532    WWF No Mercy USA-1 VARIANT Nintendo 64 N64 Car...\n",
      "46729    WWF No Mercy USA-1 VARIANT Nintendo 64 N64 Car...\n",
      "46949    WWF No Mercy USA-1 VARIANT Nintendo 64 N64 Car...\n",
      "47172    WWF No Mercy USA-1 VARIANT Nintendo 64 N64 Car...\n",
      "47375    WWF No Mercy USA-1 VARIANT Nintendo 64 N64 Car...\n",
      "Name: text, Length: 86, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_posts[df_posts['user'] == 'reginabarnes']['text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
